{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e63d688e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Flask in c:\\users\\saanvi tayal\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\saanvi tayal\\anaconda3\\lib\\site-packages (from Flask) (2.0.1)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\saanvi tayal\\anaconda3\\lib\\site-packages (from Flask) (2.0.2)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\saanvi tayal\\anaconda3\\lib\\site-packages (from Flask) (2.11.3)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\saanvi tayal\\anaconda3\\lib\\site-packages (from Flask) (8.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\saanvi tayal\\anaconda3\\lib\\site-packages (from click>=5.1->Flask) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\saanvi tayal\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->Flask) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install Flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9fb365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprting packages\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "#import pyttsx3\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d85f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Function which takes a text file as parameter and convert the text into audio,when the function is called.\n",
    "# engine = pyttsx3.init()\n",
    "# def text2speech(text_file):\n",
    "#     pose=text_file\n",
    "#     f=open(pose,'r')\n",
    "#     text=f.read()\n",
    "#     f.close()\n",
    "#     engine.setProperty('rate',150)\n",
    "#     engine.say(text)\n",
    "#     engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcbd4775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate angles between two bones which will be used further.\n",
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aaac0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "def gen_frame ():\n",
    "    while True:\n",
    "        sucess,frame = camera.read()\n",
    "        if not sucess:\n",
    "            break\n",
    "        else:\n",
    "            ret,buffer = cv2.imencode('.jpg',frame)\n",
    "            frame=buffer.tobytes()\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a04e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [19/Jan/2024 14:11:34] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:11:34] \"GET /main.js HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:16:53] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:16:53] \"GET /main.js HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:17:29] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:17:29] \"GET /main.js HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:17:38] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:17:39] \"GET /main.js HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:18:16] \"GET /cardio HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:18:16] \"GET /static/js/main.js HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:18:44] \"GET /cardio HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:18:44] \"GET /static/js/main.js HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:19:02] \"GET /cardio HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:19:02] \"GET /static/js/main.js HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:22:42] \"GET /static/js/main.js HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:22:44] \"GET /cardio HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jan/2024 14:22:44] \"GET /static/js/main.js HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, Response\n",
    "import os \n",
    "import json\n",
    "app = Flask(__name__,template_folder=os.path.abspath('../AI-YOGA-GURU-V2/templates'),static_folder=os.path.abspath('../AI-YOGA-GURU-V2/static'))\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    return Response(gen_frame(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/cardio')\n",
    "def cardio():\n",
    "    return render_template('cardio.html')\n",
    "if __name__==\"__main__\":\n",
    "    app.run(debug=False,port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9252f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Saanvi Tayal\\OneDrive\\Documents\\Visual Studio 2019\\AI-YOGA-GURU-MAIN\\templates\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.abspath('../AI-YOGA-GURU-V2/templates'))\n",
    "C:\\Users\\Saanvi Tayal\\OneDrive\\Documents\\Visual Studio 2019\\AI-Yoga-Guru-V2\\templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4a7a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47251f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4283e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"Pictures/warrior2.jpg\")\n",
    "\n",
    "#Creating lable variable\n",
    "label=\"Unknown Pose\"\n",
    "\n",
    "# Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        ##STEP I \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            right_shoulder= [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            \n",
    "            # STEP II:Calculate angle between the joints\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle=calculate_angle(right_shoulder,right_elbow,right_wrist)\n",
    "            left_shoulder_angle = calculate_angle(left_hip, left_shoulder, left_elbow)\n",
    "            right_shoulder_angle = calculate_angle(right_hip, right_shoulder, right_elbow)\n",
    "            left_hip_angle=calculate_angle(left_knee,left_hip,left_shoulder)\n",
    "            right_hip_angle=calculate_angle(right_knee,right_hip,right_shoulder)\n",
    "            left_knee_angle=calculate_angle(left_ankle,left_knee,left_hip)\n",
    "            right_knee_angle=calculate_angle(right_ankle,right_knee,right_hip)\n",
    "           \n",
    "            #STEP III: Classifing poses\n",
    "            #Check if hands are staright or not\n",
    "            if left_elbow_angle > 165 and left_elbow_angle < 195 and right_elbow_angle > 165 and right_elbow_angle < 195:\n",
    "                if left_shoulder_angle > 80 and left_shoulder_angle < 110 and right_shoulder_angle > 80 and right_shoulder_angle < 110:\n",
    "                    #Warrior II pose\n",
    "                    if left_knee_angle > 165 and left_knee_angle < 195 or right_knee_angle > 165 and right_knee_angle < 195:\n",
    "                        if left_knee_angle > 90 and left_knee_angle < 120 or right_knee_angle > 90 and right_knee_angle < 120:\n",
    "                            label=\"warrior II Pose\"\n",
    "                            text2speech(\"Warrior_II.txt\")\n",
    "                    #T Pose\n",
    "                    if left_knee_angle > 160 and left_knee_angle < 195 and right_knee_angle > 160 and right_knee_angle < 195:\n",
    "                        label = 'T Pose'    \n",
    "                        text2speech(\"TPose.txt\")\n",
    "            #Tree Pose\n",
    "            if left_knee_angle > 165 and left_knee_angle < 195 or right_knee_angle > 165 and right_knee_angle < 195 :\n",
    "                if left_knee_angle > 315 and left_knee_angle < 335 or right_knee_angle > 25 and right_knee_angle < 45 :\n",
    "                    label = 'Tree Pose'\n",
    "                    text2speech(\"treepose.txt\")\n",
    "                    \n",
    "            else:\n",
    "                label = 'Unknown Pose'\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #Showing label on the output screen\n",
    "        cv2.putText(image, label,(10,60),cv2.FONT_HERSHEY_SIMPLEX, 1,(0,255,0), 1, cv2.LINE_AA)\n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2))\n",
    "                \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e136926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d92d304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
